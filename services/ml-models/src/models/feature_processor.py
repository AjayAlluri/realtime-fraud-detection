"""
Feature Processor for preparing and validating features for ML model inference.
Handles feature transformation, validation, and compatibility with Flink pipeline features.
"""
import asyncio
import time
import logging
from typing import Dict, Any, List, Optional, Union, Tuple
from datetime import datetime, timezone
from dataclasses import dataclass
from enum import Enum

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler

from utils.config import Config
from utils.logging_config import get_logger


class FeatureType(Enum):
    """Types of features supported."""
    NUMERICAL = "numerical"
    CATEGORICAL = "categorical"
    TEMPORAL = "temporal"
    TEXT = "text"
    BINARY = "binary"


@dataclass
class FeatureDefinition:
    """Definition of a feature including its type and processing rules."""
    name: str
    feature_type: FeatureType
    required: bool = False
    min_value: Optional[float] = None
    max_value: Optional[float] = None
    default_value: Optional[Union[float, str, int]] = None
    categories: Optional[List[str]] = None
    normalization: Optional[str] = None  # 'standard', 'robust', 'minmax'


class FeatureProcessor:
    """
    Processes and validates features for ML model inference.
    Ensures compatibility with features generated by the Flink pipeline.
    """
    
    def __init__(self, config: Config):
        self.config = config
        self.logger = get_logger("feature_processor")
        
        # Feature definitions (based on Flink pipeline features)
        self.feature_definitions = self._initialize_feature_definitions()
        
        # Scalers for different feature types
        self.scalers = {}
        self._initialize_scalers()
        
        # Feature validation cache
        self.validation_cache = {}
        self.cache_ttl_seconds = 300  # 5 minutes
        
        self.logger.info(f"Feature processor initialized with {len(self.feature_definitions)} feature definitions")
    
    def _initialize_feature_definitions(self) -> Dict[str, FeatureDefinition]:
        """Initialize feature definitions matching Flink pipeline output."""
        definitions = {}
        
        # Amount-based features
        definitions.update({
            "amount": FeatureDefinition("amount", FeatureType.NUMERICAL, required=True, min_value=0.0, normalization="robust"),
            "amount_log": FeatureDefinition("amount_log", FeatureType.NUMERICAL, default_value=0.0, normalization="standard"),
            "amount_percentile": FeatureDefinition("amount_percentile", FeatureType.NUMERICAL, min_value=0.0, max_value=100.0, normalization="minmax"),
            "amount_zscore": FeatureDefinition("amount_zscore", FeatureType.NUMERICAL, normalization="standard"),
            "rounded_amount_frequency": FeatureDefinition("rounded_amount_frequency", FeatureType.NUMERICAL, min_value=0.0, normalization="robust"),
        })
        
        # Temporal features
        definitions.update({
            "hour_of_day": FeatureDefinition("hour_of_day", FeatureType.NUMERICAL, min_value=0, max_value=23, default_value=12),
            "day_of_week": FeatureDefinition("day_of_week", FeatureType.NUMERICAL, min_value=0, max_value=6, default_value=1),
            "is_weekend": FeatureDefinition("is_weekend", FeatureType.BINARY, default_value=0),
            "is_holiday": FeatureDefinition("is_holiday", FeatureType.BINARY, default_value=0),
            "time_since_last_transaction": FeatureDefinition("time_since_last_transaction", FeatureType.NUMERICAL, min_value=0.0, normalization="robust"),
        })
        
        # Geographic features
        definitions.update({
            "distance_from_home": FeatureDefinition("distance_from_home", FeatureType.NUMERICAL, min_value=0.0, normalization="robust"),
            "location_risk_score": FeatureDefinition("location_risk_score", FeatureType.NUMERICAL, min_value=0.0, max_value=1.0, normalization="minmax"),
            "country_risk_score": FeatureDefinition("country_risk_score", FeatureType.NUMERICAL, min_value=0.0, max_value=1.0, default_value=0.5),
            "timezone_mismatch": FeatureDefinition("timezone_mismatch", FeatureType.BINARY, default_value=0),
        })
        
        # User behavior features
        definitions.update({
            "user_transaction_count_1h": FeatureDefinition("user_transaction_count_1h", FeatureType.NUMERICAL, min_value=0, normalization="robust"),
            "user_transaction_count_24h": FeatureDefinition("user_transaction_count_24h", FeatureType.NUMERICAL, min_value=0, normalization="robust"),
            "user_total_amount_24h": FeatureDefinition("user_total_amount_24h", FeatureType.NUMERICAL, min_value=0.0, normalization="robust"),
            "user_avg_amount": FeatureDefinition("user_avg_amount", FeatureType.NUMERICAL, min_value=0.0, normalization="robust"),
            "user_unique_merchants_24h": FeatureDefinition("user_unique_merchants_24h", FeatureType.NUMERICAL, min_value=0, normalization="robust"),
            "user_account_age_days": FeatureDefinition("user_account_age_days", FeatureType.NUMERICAL, min_value=0, normalization="robust"),
        })
        
        # Merchant features
        definitions.update({
            "merchant_transaction_count_1h": FeatureDefinition("merchant_transaction_count_1h", FeatureType.NUMERICAL, min_value=0, normalization="robust"),
            "merchant_fraud_rate": FeatureDefinition("merchant_fraud_rate", FeatureType.NUMERICAL, min_value=0.0, max_value=1.0, default_value=0.0),
            "merchant_avg_amount": FeatureDefinition("merchant_avg_amount", FeatureType.NUMERICAL, min_value=0.0, normalization="robust"),
            "merchant_risk_score": FeatureDefinition("merchant_risk_score", FeatureType.NUMERICAL, min_value=0.0, max_value=1.0, default_value=0.5),
            "merchant_category_risk": FeatureDefinition("merchant_category_risk", FeatureType.NUMERICAL, min_value=0.0, max_value=1.0, default_value=0.5),
        })
        
        # Device and network features
        definitions.update({
            "device_risk_score": FeatureDefinition("device_risk_score", FeatureType.NUMERICAL, min_value=0.0, max_value=1.0, default_value=0.5),
            "is_new_device": FeatureDefinition("is_new_device", FeatureType.BINARY, default_value=0),
            "ip_risk_score": FeatureDefinition("ip_risk_score", FeatureType.NUMERICAL, min_value=0.0, max_value=1.0, default_value=0.5),
            "is_tor_ip": FeatureDefinition("is_tor_ip", FeatureType.BINARY, default_value=0),
            "is_vpn_ip": FeatureDefinition("is_vpn_ip", FeatureType.BINARY, default_value=0),
        })
        
        # Velocity features
        definitions.update({
            "velocity_score": FeatureDefinition("velocity_score", FeatureType.NUMERICAL, min_value=0.0, max_value=1.0, default_value=0.0),
            "amount_velocity_1h": FeatureDefinition("amount_velocity_1h", FeatureType.NUMERICAL, min_value=0.0, normalization="robust"),
            "transaction_velocity_5m": FeatureDefinition("transaction_velocity_5m", FeatureType.NUMERICAL, min_value=0.0, normalization="robust"),
        })
        
        # Contextual features
        definitions.update({
            "payment_method_risk": FeatureDefinition("payment_method_risk", FeatureType.NUMERICAL, min_value=0.0, max_value=1.0, default_value=0.5),
            "card_type_risk": FeatureDefinition("card_type_risk", FeatureType.NUMERICAL, min_value=0.0, max_value=1.0, default_value=0.5),
            "is_crypto_merchant": FeatureDefinition("is_crypto_merchant", FeatureType.BINARY, default_value=0),
            "is_gift_card_merchant": FeatureDefinition("is_gift_card_merchant", FeatureType.BINARY, default_value=0),
            "cross_border_transaction": FeatureDefinition("cross_border_transaction", FeatureType.BINARY, default_value=0),
        })
        
        # Categorical features (encoded as numerical)
        definitions.update({
            "payment_method_encoded": FeatureDefinition("payment_method_encoded", FeatureType.NUMERICAL, min_value=0, max_value=10, default_value=0),
            "merchant_category_encoded": FeatureDefinition("merchant_category_encoded", FeatureType.NUMERICAL, min_value=0, max_value=20, default_value=0),
            "card_type_encoded": FeatureDefinition("card_type_encoded", FeatureType.NUMERICAL, min_value=0, max_value=5, default_value=0),
        })
        
        return definitions
    
    def _initialize_scalers(self) -> None:
        """Initialize feature scalers."""
        self.scalers = {
            "standard": StandardScaler(),
            "robust": RobustScaler(),
            "minmax": MinMaxScaler()
        }
        
        # In production, these would be fitted on training data
        # For now, we'll use them without fitting (identity transformation)
        self.scalers_fitted = False
    
    async def process_features(self, raw_features: Dict[str, Any]) -> Dict[str, Any]:
        """
        Process raw features for ML model inference.
        
        Args:
            raw_features: Raw feature dictionary from transaction
            
        Returns:
            Processed and validated feature dictionary
        """
        start_time = time.time()
        
        try:
            # Extract and validate features
            processed_features = await self._extract_and_validate_features(raw_features)
            
            # Apply transformations
            transformed_features = await self._apply_transformations(processed_features)
            
            # Generate derived features
            enhanced_features = await self._generate_derived_features(transformed_features, raw_features)
            
            # Final validation
            validated_features = await self._final_validation(enhanced_features)
            
            processing_time_ms = (time.time() - start_time) * 1000
            
            self.logger.debug(f"Feature processing completed in {processing_time_ms:.2f}ms")
            
            return validated_features
            
        except Exception as e:
            self.logger.error(f"Error processing features: {str(e)}")
            raise
    
    async def _extract_and_validate_features(self, raw_features: Dict[str, Any]) -> Dict[str, Any]:
        """Extract and validate features based on definitions."""
        processed = {}
        
        # Process features from Flink pipeline
        flink_features = raw_features.get("features", {})
        
        for name, definition in self.feature_definitions.items():
            value = None
            
            # Try to get value from different sources
            if name in raw_features:
                value = raw_features[name]
            elif name in flink_features:
                value = flink_features[name]
            elif definition.default_value is not None:
                value = definition.default_value
            elif definition.required:
                raise ValueError(f"Required feature '{name}' not found")
            else:
                # Use default based on type
                value = self._get_default_value_for_type(definition.feature_type)
            
            # Validate and convert value
            processed[name] = self._validate_feature_value(value, definition)
        
        return processed
    
    def _validate_feature_value(self, value: Any, definition: FeatureDefinition) -> Union[float, int]:
        """Validate and convert a feature value."""
        try:
            if definition.feature_type == FeatureType.NUMERICAL:
                float_value = float(value) if value is not None else 0.0
                
                # Apply bounds
                if definition.min_value is not None:
                    float_value = max(float_value, definition.min_value)
                if definition.max_value is not None:
                    float_value = min(float_value, definition.max_value)
                
                # Handle NaN and infinity
                if np.isnan(float_value) or np.isinf(float_value):
                    float_value = definition.default_value if definition.default_value is not None else 0.0
                
                return float_value
                
            elif definition.feature_type == FeatureType.BINARY:
                if isinstance(value, bool):
                    return 1.0 if value else 0.0
                elif isinstance(value, str):
                    return 1.0 if value.lower() in ['true', '1', 'yes'] else 0.0
                else:
                    return 1.0 if float(value) > 0.5 else 0.0
                    
            elif definition.feature_type == FeatureType.CATEGORICAL:
                # Convert categorical to numerical encoding
                if definition.categories and value in definition.categories:
                    return float(definition.categories.index(value))
                else:
                    return definition.default_value if definition.default_value is not None else 0.0
                    
            elif definition.feature_type == FeatureType.TEMPORAL:
                # Handle temporal features
                if isinstance(value, str):
                    # Try to parse datetime
                    try:
                        dt = datetime.fromisoformat(value.replace('Z', '+00:00'))
                        return float(dt.timestamp())
                    except:
                        return definition.default_value if definition.default_value is not None else 0.0
                else:
                    return float(value) if value is not None else 0.0
                    
            else:
                # Default to numerical conversion
                return float(value) if value is not None else 0.0
                
        except (ValueError, TypeError) as e:
            self.logger.warning(f"Error validating feature {definition.name}: {str(e)}")
            return definition.default_value if definition.default_value is not None else 0.0
    
    def _get_default_value_for_type(self, feature_type: FeatureType) -> Union[float, int, str]:
        """Get default value based on feature type."""
        if feature_type == FeatureType.NUMERICAL:
            return 0.0
        elif feature_type == FeatureType.BINARY:
            return 0.0
        elif feature_type == FeatureType.CATEGORICAL:
            return 0.0
        elif feature_type == FeatureType.TEMPORAL:
            return 0.0
        else:
            return 0.0
    
    async def _apply_transformations(self, features: Dict[str, Any]) -> Dict[str, Any]:
        """Apply feature transformations."""
        transformed = features.copy()
        
        for name, value in features.items():
            if name in self.feature_definitions:
                definition = self.feature_definitions[name]
                
                if definition.normalization and self.scalers_fitted:
                    # Apply normalization (in production, use fitted scalers)
                    scaler = self.scalers.get(definition.normalization)
                    if scaler:
                        # For now, apply simple standardization
                        if definition.normalization == "standard":
                            transformed[name] = self._simple_standardize(value)
                        elif definition.normalization == "robust":
                            transformed[name] = self._simple_robust_scale(value)
                        elif definition.normalization == "minmax":
                            transformed[name] = self._simple_minmax_scale(value, definition)
        
        return transformed
    
    def _simple_standardize(self, value: float) -> float:
        """Simple standardization (placeholder for fitted scaler)."""
        # This is a placeholder - in production, use fitted StandardScaler
        return np.clip(value / 1000.0, -5.0, 5.0)  # Simple scaling
    
    def _simple_robust_scale(self, value: float) -> float:
        """Simple robust scaling (placeholder for fitted scaler)."""
        # This is a placeholder - in production, use fitted RobustScaler
        return np.clip(value / 100.0, -10.0, 10.0)  # Simple scaling
    
    def _simple_minmax_scale(self, value: float, definition: FeatureDefinition) -> float:
        """Simple min-max scaling."""
        if definition.min_value is not None and definition.max_value is not None:
            range_val = definition.max_value - definition.min_value
            if range_val > 0:
                return (value - definition.min_value) / range_val
        return value
    
    async def _generate_derived_features(self, features: Dict[str, Any], raw_features: Dict[str, Any]) -> Dict[str, Any]:
        """Generate derived features from base features."""
        enhanced = features.copy()
        
        # Amount-based derived features
        amount = features.get("amount", 0.0)
        if amount > 0:
            enhanced["amount_log"] = np.log1p(amount)
            enhanced["amount_sqrt"] = np.sqrt(amount)
        
        # Ratio features
        user_avg = features.get("user_avg_amount", 1.0)
        if user_avg > 0:
            enhanced["amount_to_user_avg_ratio"] = amount / user_avg
        
        merchant_avg = features.get("merchant_avg_amount", 1.0)
        if merchant_avg > 0:
            enhanced["amount_to_merchant_avg_ratio"] = amount / merchant_avg
        
        # Velocity-based features
        tx_count_1h = features.get("user_transaction_count_1h", 0)
        tx_count_24h = features.get("user_transaction_count_24h", 0)
        if tx_count_24h > 0:
            enhanced["hourly_velocity_ratio"] = tx_count_1h / (tx_count_24h / 24)
        
        # Risk score combinations
        device_risk = features.get("device_risk_score", 0.5)
        ip_risk = features.get("ip_risk_score", 0.5)
        enhanced["combined_device_ip_risk"] = (device_risk + ip_risk) / 2
        
        # Temporal features
        hour = features.get("hour_of_day", 12)
        enhanced["is_business_hours"] = 1.0 if 9 <= hour <= 17 else 0.0
        enhanced["is_late_night"] = 1.0 if hour < 6 or hour > 22 else 0.0
        
        # Add metadata features
        enhanced["transaction_id"] = raw_features.get("transaction_id", "")
        enhanced["user_id"] = raw_features.get("user_id", "")
        enhanced["merchant_id"] = raw_features.get("merchant_id", "")
        enhanced["timestamp"] = raw_features.get("timestamp", "")
        enhanced["currency"] = raw_features.get("currency", "USD")
        enhanced["payment_method"] = raw_features.get("payment_method", "unknown")
        
        return enhanced
    
    async def _final_validation(self, features: Dict[str, Any]) -> Dict[str, Any]:
        """Perform final validation and cleanup."""
        validated = {}
        
        for name, value in features.items():
            if isinstance(value, (int, float)):
                # Ensure numerical values are finite
                if np.isfinite(value):
                    validated[name] = value
                else:
                    # Replace infinite or NaN values
                    if name in self.feature_definitions:
                        default_val = self.feature_definitions[name].default_value
                        validated[name] = default_val if default_val is not None else 0.0
                    else:
                        validated[name] = 0.0
            else:
                # Non-numerical features (metadata)
                validated[name] = value
        
        # Ensure we have minimum required features
        required_features = [name for name, defn in self.feature_definitions.items() if defn.required]
        missing_required = [name for name in required_features if name not in validated]
        
        if missing_required:
            raise ValueError(f"Missing required features: {missing_required}")
        
        return validated
    
    def get_feature_names(self) -> List[str]:
        """Get list of all feature names."""
        return list(self.feature_definitions.keys())
    
    def get_numerical_feature_names(self) -> List[str]:
        """Get list of numerical feature names."""
        return [
            name for name, defn in self.feature_definitions.items()
            if defn.feature_type in [FeatureType.NUMERICAL, FeatureType.BINARY]
        ]
    
    def validate_feature_schema(self, features: Dict[str, Any]) -> Tuple[bool, List[str]]:
        """Validate that features match expected schema."""
        errors = []
        
        # Check required features
        required_features = [name for name, defn in self.feature_definitions.items() if defn.required]
        missing_required = [name for name in required_features if name not in features]
        
        if missing_required:
            errors.append(f"Missing required features: {missing_required}")
        
        # Check feature types and ranges
        for name, value in features.items():
            if name in self.feature_definitions:
                defn = self.feature_definitions[name]
                
                try:
                    if defn.feature_type == FeatureType.NUMERICAL:
                        float_val = float(value)
                        if defn.min_value is not None and float_val < defn.min_value:
                            errors.append(f"Feature {name} below minimum: {float_val} < {defn.min_value}")
                        if defn.max_value is not None and float_val > defn.max_value:
                            errors.append(f"Feature {name} above maximum: {float_val} > {defn.max_value}")
                            
                except (ValueError, TypeError):
                    errors.append(f"Feature {name} has invalid type: {type(value)}")
        
        return len(errors) == 0, errors
    
    def get_feature_statistics(self) -> Dict[str, Any]:
        """Get feature processing statistics."""
        return {
            "total_features": len(self.feature_definitions),
            "numerical_features": len([d for d in self.feature_definitions.values() if d.feature_type == FeatureType.NUMERICAL]),
            "binary_features": len([d for d in self.feature_definitions.values() if d.feature_type == FeatureType.BINARY]),
            "categorical_features": len([d for d in self.feature_definitions.values() if d.feature_type == FeatureType.CATEGORICAL]),
            "required_features": len([d for d in self.feature_definitions.values() if d.required]),
            "scalers_fitted": self.scalers_fitted,
            "cache_size": len(self.validation_cache)
        }